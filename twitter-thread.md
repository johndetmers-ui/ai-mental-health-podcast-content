# Twitter/X Thread

**Tweet 1 (Hook):**
Stanford just dropped a fascinating panel on AI in mental health care.

3 researchers. 47 minutes. Here's what they said about where psychiatry is heading â€” and why the ethics matter as much as the tech.

A thread. ðŸ§µ

**Tweet 2:**
The big picture: AI isn't just powering therapy chatbots anymore.

Stanford's Dr. Adeli is building "ambient intelligence" â€” in-home sensors + AI that passively monitor psychiatric symptoms like a smartwatch monitors heart rate.

No questionnaires. No self-reporting. Just continuous, non-intrusive data.

**Tweet 3:**
His lab also built a multimodal AI tool that screens for depression and anxiety during pre-visit rooming.

It analyzes video, audio, AND language content in real time.

Early results are promising. They're already integrating it into clinical workflows.

**Tweet 4:**
But here's the real game-changer: neural fingerprints.

Dr. Superar's team is creating brain-based biomarkers using imaging + AI that can predict which treatment will work for a patient BEFORE they start it.

No more trial-and-error prescribing with harsh side effects.

**Tweet 5:**
The ethics panel hit different though.

Dr. Martinez Martin (Stanford bioethics) pointed out that ambient intelligence collects data while people live their daily lives.

Old privacy frameworks don't cover this. Consent isn't enough when people don't understand downstream risks.

**Tweet 6:**
The bias problem is deeper than most people realize.

Black and Latino men are disproportionately diagnosed with schizophrenia â€” driven by clinician bias and systemic inequities.

Train an AI on those health records? You bake the bias into the foundation.

Technical fixes alone won't solve this.

**Tweet 7:**
Their solution: a "pipeline approach."

Scrutinize every step â€” from what questions you ask of the data, to who builds the tool, to who gets access.

Bring in historians, sociologists, anthropologists. Not just engineers.

Stanford's HAI already does this with an interdisciplinary ethics board.

**Tweet 8:**
Dr. Adeli's boldest prediction:

Within a decade, generative AI won't just diagnose â€” it'll plan and optimize non-invasive brain stimulation treatments for depression and anxiety.

Same way gen AI is revolutionizing drug discovery, but for neuromodulation.

**Tweet 9:**
The recurring theme from all 3 researchers:

AI should AUGMENT human clinicians, not replace them.

"Human connections remain irreplaceable in understanding the complexity of mental health."

The creativity therapists bring to patient care isn't something you can automate.

**Tweet 10:**
The tech is moving fast. The question is whether ethics, regulation, and clinical education can keep pace.

Full episode worth watching: youtube.com/watch?v=i1wiT43nt48

What's your take â€” are we building the guardrails fast enough? ðŸ‘‡
